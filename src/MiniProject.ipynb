{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f5fb4d1-0f91-4af2-ac62-3dc7315ddae1",
   "metadata": {},
   "source": [
    "## D7041E - Mini Project Group 9 - Elvira Forslund Widenroth & Jenny SundstrÃ¶m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7e6da20f-77fe-41b3-92c4-15ecd43f0424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import itertools\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "210db504-7bd9-4d85-a361-6e083e4d5871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to define the neural network\n",
    "class Multiclass(nn.Module):\n",
    "    def __init__(self, input_size, hidden_neurons, hidden_layers, output_size):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_size, hidden_neurons))\n",
    "        layers.append(nn.ReLU())\n",
    "        for _ in range(hidden_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_neurons, hidden_neurons))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(hidden_neurons, output_size))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "909c6b65-8f09-4612-a3d3-a82a51eca8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for training the model\n",
    "def train_model(model, optimizer, X_train, y_train, num_epochs, batch_size, loss_fn):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        indices = torch.randperm(len(X_train))\n",
    "        X_train_shuffled, y_train_shuffled = X_train[indices], y_train[indices]\n",
    "\n",
    "        for i in range(0, len(X_train), batch_size):\n",
    "            X_batch = X_train_shuffled[i:i + batch_size]\n",
    "            y_batch = y_train_shuffled[i:i + batch_size]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, torch.argmax(y_batch, 1))\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "57a36777-2ec4-417b-ba81-809dbf4bea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model on a dataset and calculate accuracy\n",
    "def evaluate_model(model, X, y):\n",
    "    model.eval()\n",
    "    y_pred = model(X)\n",
    "    acc = (torch.argmax(y_pred, 1) == torch.argmax(y, 1)).float().mean().item()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "251d11ad-647b-4098-90ff-e08a0d7ad93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to perform nested k-fold cross-validation\n",
    "def nested_cross_validation(X, y, hyperparameters, input_size, output_size, outer_splits, inner_splits, seed):\n",
    "    y_labels = np.argmax(y, axis=1)\n",
    "    outer_kfold = StratifiedKFold(n_splits=outer_splits, shuffle=True, random_state=seed)\n",
    "    outer_test_accuracies = []\n",
    "    outer_test_f1_scores = []\n",
    "    outer_test_precisions = []\n",
    "    outer_test_recalls = []\n",
    "    all_best_hyperparameters = [] \n",
    "\n",
    "\n",
    "    for outer_train_index, outer_test_index in outer_kfold.split(X,y_labels):\n",
    "        X_outer_train, X_outer_test = X[outer_train_index], X[outer_test_index]\n",
    "        y_outer_train, y_outer_test = y[outer_train_index], y[outer_test_index]\n",
    "\n",
    "        y_labels_outer_train = np.argmax(y_outer_train, axis=1)\n",
    "\n",
    "        best_acc = -np.inf\n",
    "        best_weights = None\n",
    "        best_hyperparameters = None\n",
    "\n",
    "        inner_kfold = StratifiedKFold(n_splits=inner_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "        for hyperparam_set in hyperparameters:\n",
    "            lr = hyperparam_set['learning_rate']\n",
    "            hidden_neurons = hyperparam_set['hidden_neurons']\n",
    "            hidden_layers = hyperparam_set['hidden_layers']\n",
    "            num_epochs = hyperparam_set['num_epochs']\n",
    "            loss_fn = hyperparam_set['loss_function']\n",
    "\n",
    "            model = Multiclass(input_size=input_size, hidden_neurons=hidden_neurons, hidden_layers=hidden_layers, output_size=output_size)\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "            for inner_train_index, inner_val_index in inner_kfold.split(X_outer_train, y_labels_outer_train):\n",
    "                X_inner_train, X_inner_val = X_outer_train[inner_train_index], X_outer_train[inner_val_index]\n",
    "                y_inner_train, y_inner_val = y_outer_train[inner_train_index], y_outer_train[inner_val_index]\n",
    "\n",
    "                train_model(model, optimizer, X_inner_train, y_inner_train, num_epochs, batch_size, loss_fn)\n",
    "\n",
    "                acc_val = evaluate_model(model, X_inner_val, y_inner_val)\n",
    "\n",
    "                if acc_val > best_acc:\n",
    "                    best_acc = acc_val\n",
    "                    best_hyperparameters = hyperparam_set\n",
    "\n",
    "        model = Multiclass(input_size=input_size, hidden_neurons=best_hyperparameters['hidden_neurons'], hidden_layers=best_hyperparameters['hidden_layers'], output_size=output_size)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=best_hyperparameters['learning_rate'])\n",
    "\n",
    "        train_model(model, optimizer, X_outer_train, y_outer_train, best_hyperparameters['num_epochs'], batch_size, best_hyperparameters['loss_function'])\n",
    "\n",
    "        acc_test = evaluate_model(model, X_outer_test, y_outer_test)\n",
    "        f1, precision, recall, _ = precision_recall_fscore_support(y_outer_test.argmax(axis=1), model(X_outer_test).argmax(dim=1), average='weighted', zero_division=1)\n",
    "\n",
    "        outer_test_accuracies.append(acc_test)\n",
    "        outer_test_f1_scores.append(f1)\n",
    "        outer_test_precisions.append(precision)\n",
    "        outer_test_recalls.append(recall)\n",
    "        all_best_hyperparameters.append(best_hyperparameters) \n",
    "\n",
    "\n",
    "        print(f\"Outer Fold: Test Accuracy={acc_test * 100:.1f}%, F1 Score={f1:.4f}, Precision={precision:.4f}, Recall={recall:.4f} with Hyperparameters={best_hyperparameters}\")\n",
    "\n",
    "    return outer_test_accuracies, all_best_hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1e247a55-1728-4261-90e2-cca87cef684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to Pre-Process the data\n",
    "def preprocess_data(X, y, correlation_threshold=0.95):\n",
    "    correlated_features = set()\n",
    "    correlation_matrix = np.corrcoef(X, rowvar=False)\n",
    "    num_features = correlation_matrix.shape[0]\n",
    "\n",
    "    for i in range(num_features):\n",
    "        for j in range(i + 1, num_features):\n",
    "            if abs(correlation_matrix[i, j]) > correlation_threshold:\n",
    "                correlated_features.add(j)\n",
    "\n",
    "    X_no_correlation = np.delete(X, list(correlated_features), axis=1)\n",
    "    selector = VarianceThreshold()\n",
    "    X_no_zero_variance = selector.fit_transform(X_no_correlation)\n",
    "    X_tensor = torch.tensor(X_no_zero_variance, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    return X_tensor, y_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75451fc-e47e-484d-b6bd-f5c4a0201a83",
   "metadata": {},
   "source": [
    "### Train and Evaluate the Model on a chosen Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a44a855a-5f1a-4a8b-a8de-a286ea7eaff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "\n",
    "data = pd.DataFrame(data=wine.data, columns=wine.feature_names)\n",
    "data['target'] = wine.target\n",
    "\n",
    "X = data.iloc[:, :-1].values\n",
    "y = pd.get_dummies(data.iloc[:, -1]).values\n",
    "\n",
    "X, y = preprocess_data(X, y)\n",
    "batch_size = 30\n",
    "input_size = 13\n",
    "output_size = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ad283a-e4e5-455d-a175-98adb5a58f23",
   "metadata": {},
   "source": [
    "### Method for Tuning Hyperparameters\n",
    "In order to choose the Hyper Parameters, we started by reading about the values for the Neural Network. We then initialize the hyperparameters as:\n",
    "\n",
    "**Lr** :Between 0-1\n",
    "\n",
    "**Hidden Neurons**: Between output size & feature size (3-13, start with 8)\n",
    "\n",
    "**Hidden Layers**: 1-2 for small number of features (start with 2)\n",
    "\n",
    "**Number of Epochs**: Around 10\n",
    "\n",
    "**Loss Function**: Cross Entropy\n",
    "\n",
    "We then go through the hyper parameters one by one and tune them accordingly to achive higher accuracy. The performance of each test is documented by Accuracy, F1 score, Recall and Precision. However, the model uses Accuracy as the metric during training. \n",
    "\n",
    "The tests for Hyper Parameter Tuning is done by running 5 tests on the data, where a 3-time fold is applied (5x3 = 15 tests)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3874866b-bf5b-4804-abd1-7d406bd0ab4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_experiments = 5\n",
    "outer_splits=3 #k-folds outer\n",
    "inner_splits=3 #k-folds inner\n",
    "seed = 42 #same seed used when tuning Hyper Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede37915-df0b-46f0-83d3-0d1ccca661a4",
   "metadata": {},
   "source": [
    "### Varying Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "da2e5b30-6e81-4865-83e4-d9c30bfbc091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Fold: Test Accuracy=40.0%, F1 Score=0.7600, Precision=0.4000, Recall=0.2286 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=33.9%, F1 Score=0.7759, Precision=0.3390, Recall=0.1716 with Hyperparameters={'learning_rate': 0.001, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=62.7%, F1 Score=0.7285, Precision=0.6271, Recall=0.5288 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=91.7%, F1 Score=0.9241, Precision=0.9167, Recall=0.9171 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=71.2%, F1 Score=0.7233, Precision=0.7119, Recall=0.6629 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=40.7%, F1 Score=0.7587, Precision=0.4068, Recall=0.2352 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=63.3%, F1 Score=0.7361, Precision=0.6333, Recall=0.5376 with Hyperparameters={'learning_rate': 0.001, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=91.5%, F1 Score=0.9190, Precision=0.9153, Recall=0.9156 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=71.2%, F1 Score=0.7382, Precision=0.7119, Recall=0.7158 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=40.0%, F1 Score=0.7600, Precision=0.4000, Recall=0.2286 with Hyperparameters={'learning_rate': 0.1, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=67.8%, F1 Score=0.7786, Precision=0.6780, Recall=0.5771 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=66.1%, F1 Score=0.7046, Precision=0.6610, Recall=0.6740 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=61.7%, F1 Score=0.5952, Precision=0.6167, Recall=0.6033 with Hyperparameters={'learning_rate': 0.001, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=66.1%, F1 Score=0.5028, Precision=0.6610, Recall=0.8396 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=88.1%, F1 Score=0.8985, Precision=0.8814, Recall=0.8807 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "\n",
      "Votes for Learning Rates: {0.01: 11, 0.001: 3, 0.1: 1}\n",
      "The Learning Rate with the most votes: 0.01\n",
      "Average Test Accuracy Across Folds: 72.0%\n"
     ]
    }
   ],
   "source": [
    "hyperparameters_to_tune = [\n",
    "    {'learning_rate': 0.00001, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': nn.CrossEntropyLoss()},\n",
    "    {'learning_rate': 0.0001, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': nn.CrossEntropyLoss()},\n",
    "    {'learning_rate': 0.001, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': nn.CrossEntropyLoss()},\n",
    "    {'learning_rate': 0.01, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': nn.CrossEntropyLoss()},\n",
    "    {'learning_rate': 0.1, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': nn.CrossEntropyLoss()},\n",
    "    {'learning_rate': 0.99, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': nn.CrossEntropyLoss()},\n",
    "\n",
    "]\n",
    "\n",
    "all_best_hyperparameters = []\n",
    "\n",
    "for _ in range(num_experiments):\n",
    "    test_accuracies_manual_tuning, best_hyperparameters_each_fold = nested_cross_validation(X, y, hyperparameters_to_tune, input_size, output_size, outer_splits=outer_splits, inner_splits=inner_splits, seed=seed)\n",
    "    all_best_hyperparameters.append(best_hyperparameters_each_fold)\n",
    "    \n",
    "learning_rate_votes = {}\n",
    "for results in all_best_hyperparameters:\n",
    "    for hyperparameters in results:\n",
    "        learning_rate = hyperparameters['learning_rate']\n",
    "        learning_rate_votes[learning_rate] = learning_rate_votes.get(learning_rate, 0) + 1\n",
    "        \n",
    "best_learning_rate = max(learning_rate_votes, key=learning_rate_votes.get)\n",
    "average_test_accuracy = np.mean(test_accuracies_manual_tuning)\n",
    "print()\n",
    "print(f\"Votes for Learning Rates: {learning_rate_votes}\")\n",
    "print(f\"The Learning Rate with the most votes: {best_learning_rate}\")\n",
    "print(f\"Average Test Accuracy Across Folds: {average_test_accuracy * 100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2549df91-632a-42a4-b08d-d987ffeb61a3",
   "metadata": {},
   "source": [
    "**We ran this a couple of times to find that the learning rates that recieved the highest amount of votes for the best accuracy alternates between lr = 0.01 and lr = 0.001. We choose to continue the experiment and tuning of hyperparameters with lr = 0.01.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeecafd-14b0-4a40-93c4-137a7f3c143d",
   "metadata": {},
   "source": [
    "### Varying number of Hidden Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0b994bd4-1adc-4d96-89dd-e9b1d674dfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Fold: Test Accuracy=40.0%, F1 Score=0.7600, Precision=0.4000, Recall=0.2286 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=86.4%, F1 Score=0.8890, Precision=0.8644, Recall=0.8605 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=40.7%, F1 Score=0.7587, Precision=0.4068, Recall=0.2352 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 5, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=61.7%, F1 Score=0.7293, Precision=0.6167, Recall=0.5259 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=91.5%, F1 Score=0.9162, Precision=0.9153, Recall=0.9153 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=79.7%, F1 Score=0.8382, Precision=0.7966, Recall=0.7788 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=88.3%, F1 Score=0.8915, Precision=0.8833, Recall=0.8834 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 10, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=84.7%, F1 Score=0.8703, Precision=0.8475, Recall=0.8438 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=98.3%, F1 Score=0.9839, Precision=0.9831, Recall=0.9831 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 5, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=40.0%, F1 Score=0.7600, Precision=0.4000, Recall=0.2286 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 5, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=69.5%, F1 Score=0.7131, Precision=0.6949, Recall=0.6838 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 10, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=69.5%, F1 Score=0.7831, Precision=0.6949, Recall=0.5879 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=91.7%, F1 Score=0.9211, Precision=0.9167, Recall=0.9157 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=86.4%, F1 Score=0.8890, Precision=0.8644, Recall=0.8605 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=78.0%, F1 Score=0.8295, Precision=0.7797, Recall=0.7558 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 10, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "\n",
      "Votes for Hidden Neurons: {13: 6, 8: 3, 5: 3, 10: 3}\n",
      "The number of Hidden Neurons with the most votes: 13\n",
      "Average Test Accuracy Across Folds: 85.4%\n"
     ]
    }
   ],
   "source": [
    "hyperparameters_to_tune = [\n",
    "    {'learning_rate': 0.01, 'hidden_neurons': 1, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': nn.CrossEntropyLoss()},\n",
    "    {'learning_rate': 0.01, 'hidden_neurons': 3, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': nn.CrossEntropyLoss()},\n",
    "    {'learning_rate': 0.01, 'hidden_neurons': 5, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': nn.CrossEntropyLoss()},\n",
    "    {'learning_rate': 0.01, 'hidden_neurons': 8, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': nn.CrossEntropyLoss()},\n",
    "    {'learning_rate': 0.01, 'hidden_neurons': 10, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': nn.CrossEntropyLoss()},\n",
    "    {'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': nn.CrossEntropyLoss()},\n",
    "\n",
    "]\n",
    "all_best_hyperparameters = []\n",
    "\n",
    "for _ in range(num_experiments):\n",
    "    test_accuracies_manual_tuning, best_hyperparameters_each_fold = nested_cross_validation(X, y, hyperparameters_to_tune, input_size, output_size, outer_splits=outer_splits, inner_splits=inner_splits, seed=seed)\n",
    "    all_best_hyperparameters.append(best_hyperparameters_each_fold)\n",
    "    \n",
    "hidden_neurons_votes = {}\n",
    "for results in all_best_hyperparameters:\n",
    "    for hyperparameters in results:\n",
    "        hidden_neurons = hyperparameters['hidden_neurons']\n",
    "        hidden_neurons_votes[hidden_neurons] = hidden_neurons_votes.get(hidden_neurons, 0) + 1\n",
    "        \n",
    "best_hidden_neurons = max(hidden_neurons_votes, key=hidden_neurons_votes.get)\n",
    "average_test_accuracy = np.mean(test_accuracies_manual_tuning)\n",
    "print()\n",
    "print(f\"Votes for Hidden Neurons: {hidden_neurons_votes}\")\n",
    "print(f\"The number of Hidden Neurons with the most votes: {best_hidden_neurons}\")\n",
    "print(f\"Average Test Accuracy Across Folds: {average_test_accuracy * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b8a38f-fe63-4908-9cd4-95220e87e977",
   "metadata": {},
   "source": [
    "**Like previously we ran this part several times to conclude that the amount of hidden neurons that got the highest vote most commonly was 8 or 13 hidden neurons. We choose to continue with 13 hidden neurons.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02a50e4-a26c-4817-9b14-19a9815146d3",
   "metadata": {},
   "source": [
    "### Varying numbers of Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0fe7b538-2437-48bd-a96c-e9afaea7eb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Fold: Test Accuracy=86.7%, F1 Score=0.8747, Precision=0.8667, Recall=0.8665 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=91.5%, F1 Score=0.9153, Precision=0.9153, Recall=0.9149 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=74.6%, F1 Score=0.8069, Precision=0.7458, Recall=0.7545 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=68.3%, F1 Score=0.6905, Precision=0.6833, Recall=0.6840 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=91.5%, F1 Score=0.9153, Precision=0.9153, Recall=0.9149 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=88.1%, F1 Score=0.8857, Precision=0.8814, Recall=0.8802 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=93.3%, F1 Score=0.9334, Precision=0.9333, Recall=0.9329 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=71.2%, F1 Score=0.7302, Precision=0.7119, Recall=0.6566 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 3, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=69.5%, F1 Score=0.7056, Precision=0.6949, Recall=0.6932 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=85.0%, F1 Score=0.8792, Precision=0.8500, Recall=0.8474 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=72.9%, F1 Score=0.7993, Precision=0.7288, Recall=0.6776 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=89.8%, F1 Score=0.9016, Precision=0.8983, Recall=0.8989 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=65.0%, F1 Score=0.6646, Precision=0.6500, Recall=0.6426 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 3, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=93.2%, F1 Score=0.9352, Precision=0.9322, Recall=0.9323 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=91.5%, F1 Score=0.9229, Precision=0.9153, Recall=0.9148 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "\n",
      "Votes for Number of Hidden Layers: {2: 6, 1: 7, 3: 2}\n",
      "The Number of Hidden Layers with the most votes: 1\n",
      "Average Test Accuracy Across Folds: 83.2%\n"
     ]
    }
   ],
   "source": [
    "hyperparameters_to_tune = [\n",
    "    {'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 50, 'loss_function': nn.CrossEntropyLoss()},\n",
    "    {'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 2, 'num_epochs': 50, 'loss_function': nn.CrossEntropyLoss()},\n",
    "    {'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 3, 'num_epochs': 50, 'loss_function': nn.CrossEntropyLoss()},\n",
    "    {'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 4, 'num_epochs': 50, 'loss_function': nn.CrossEntropyLoss()},\n",
    "    {'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 5, 'num_epochs': 50, 'loss_function': nn.CrossEntropyLoss()},\n",
    "\n",
    "]\n",
    "all_best_hyperparameters = []\n",
    "\n",
    "for _ in range(num_experiments):\n",
    "    test_accuracies_manual_tuning, best_hyperparameters_each_fold = nested_cross_validation(X, y, hyperparameters_to_tune, input_size, output_size, outer_splits=outer_splits, inner_splits=inner_splits, seed=seed)\n",
    "    all_best_hyperparameters.append(best_hyperparameters_each_fold)\n",
    "    \n",
    "hidden_layers_votes = {}\n",
    "\n",
    "for results in all_best_hyperparameters:\n",
    "    for hyperparameters in results:\n",
    "        hidden_layers = hyperparameters['hidden_layers']\n",
    "        hidden_layers_votes[hidden_layers] = hidden_layers_votes.get(hidden_layers, 0) + 1\n",
    "        \n",
    "best_hidden_layers = max(hidden_layers_votes, key=hidden_layers_votes.get)\n",
    "average_test_accuracy = np.mean(test_accuracies_manual_tuning)\n",
    "print()\n",
    "print(f\"Votes for Number of Hidden Layers: {hidden_layers_votes}\")\n",
    "print(f\"The Number of Hidden Layers with the most votes: {best_hidden_layers}\")\n",
    "print(f\"Average Test Accuracy Across Folds: {average_test_accuracy * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678c04fe-6647-4398-b4fa-585a47a7dc47",
   "metadata": {},
   "source": [
    "**After trying different amount of hidden layers and re-running the votes a couple of times, it seems the most commonly voted amount of layers was 1 and the experiment continues with this setting.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23438890-c18f-47be-a12f-8c1c8f8e7cae",
   "metadata": {},
   "source": [
    "### Varying number of Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a732d598-11ed-49b6-a84f-98636c2d323b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Fold: Test Accuracy=95.0%, F1 Score=0.9503, Precision=0.9500, Recall=0.9497 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 75, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=93.2%, F1 Score=0.9338, Precision=0.9322, Recall=0.9326 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=89.8%, F1 Score=0.9052, Precision=0.8983, Recall=0.8970 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 125, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=93.3%, F1 Score=0.9344, Precision=0.9333, Recall=0.9327 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 75, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=91.5%, F1 Score=0.9183, Precision=0.9153, Recall=0.9157 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 75, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=88.1%, F1 Score=0.8985, Precision=0.8814, Recall=0.8807 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=93.3%, F1 Score=0.9382, Precision=0.9333, Recall=0.9329 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 125, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=94.9%, F1 Score=0.9558, Precision=0.9492, Recall=0.9492 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 75, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=89.8%, F1 Score=0.9063, Precision=0.8983, Recall=0.8983 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=88.3%, F1 Score=0.8968, Precision=0.8833, Recall=0.8801 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 50, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=91.5%, F1 Score=0.9181, Precision=0.9153, Recall=0.9139 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 75, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=93.2%, F1 Score=0.9419, Precision=0.9322, Recall=0.9324 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 125, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=96.7%, F1 Score=0.9676, Precision=0.9667, Recall=0.9667 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=94.9%, F1 Score=0.9515, Precision=0.9492, Recall=0.9491 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 125, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=91.5%, F1 Score=0.9299, Precision=0.9153, Recall=0.9150 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 125, 'loss_function': CrossEntropyLoss()}\n",
      "\n",
      "Votes for Number of Epochs: {75: 5, 100: 3, 125: 5, 50: 2}\n",
      "The Number of Epochs with the most votes: 75\n",
      "Average Test Accuracy Across Folds: 94.4%\n"
     ]
    }
   ],
   "source": [
    "hyperparameters_to_tune = [\n",
    "    {'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 10, 'loss_function': nn.CrossEntropyLoss()},\n",
    "    {'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 50, 'loss_function': nn.CrossEntropyLoss()},\n",
    "    {'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 75, 'loss_function': nn.CrossEntropyLoss()},\n",
    "    {'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': nn.CrossEntropyLoss()},\n",
    "    {'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 125, 'loss_function': nn.CrossEntropyLoss()},\n",
    "    {'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 150, 'loss_function': nn.CrossEntropyLoss()},\n",
    "    {'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 200, 'loss_function': nn.CrossEntropyLoss()},\n",
    "\n",
    "]\n",
    "all_best_hyperparameters = []\n",
    "\n",
    "for _ in range(num_experiments):\n",
    "    test_accuracies_manual_tuning, best_hyperparameters_each_fold = nested_cross_validation(X, y, hyperparameters_to_tune, input_size, output_size, outer_splits=outer_splits, inner_splits=inner_splits, seed=seed)\n",
    "    all_best_hyperparameters.append(best_hyperparameters_each_fold)\n",
    "    \n",
    "num_epochs_votes = {}\n",
    "\n",
    "for results in all_best_hyperparameters:\n",
    "    for hyperparameters in results:\n",
    "        num_epochs = hyperparameters['num_epochs']\n",
    "        num_epochs_votes[num_epochs] = num_epochs_votes.get(num_epochs, 0) + 1\n",
    "        \n",
    "best_num_epochs = max(num_epochs_votes, key=num_epochs_votes.get)\n",
    "average_test_accuracy = np.mean(test_accuracies_manual_tuning)\n",
    "print()\n",
    "print(f\"Votes for Number of Epochs: {num_epochs_votes}\")\n",
    "print(f\"The Number of Epochs with the most votes: {best_num_epochs}\")\n",
    "print(f\"Average Test Accuracy Across Folds: {average_test_accuracy * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b69a56-9440-45ed-82cf-5fa9b4380523",
   "metadata": {},
   "source": [
    "**The best number of Epochs seems to vary between 50, 100 and 200 for different runs. We choose 100.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fa5366-3d11-490e-a313-5fcd68ba569b",
   "metadata": {},
   "source": [
    "### Varying Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "444f093b-2d2d-495f-a00b-af2246bd1760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Fold: Test Accuracy=95.0%, F1 Score=0.9523, Precision=0.9500, Recall=0.9499 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=88.1%, F1 Score=0.8923, Precision=0.8814, Recall=0.8804 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=94.9%, F1 Score=0.9548, Precision=0.9492, Recall=0.9494 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=96.7%, F1 Score=0.9676, Precision=0.9667, Recall=0.9667 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=66.1%, F1 Score=0.4956, Precision=0.6610, Recall=0.8370 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=93.2%, F1 Score=0.9419, Precision=0.9322, Recall=0.9308 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=96.7%, F1 Score=0.9667, Precision=0.9667, Recall=0.9667 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=93.2%, F1 Score=0.9338, Precision=0.9322, Recall=0.9326 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=93.2%, F1 Score=0.9419, Precision=0.9322, Recall=0.9308 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=95.0%, F1 Score=0.9523, Precision=0.9500, Recall=0.9499 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=94.9%, F1 Score=0.9515, Precision=0.9492, Recall=0.9491 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=89.8%, F1 Score=0.9090, Precision=0.8983, Recall=0.8998 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=91.7%, F1 Score=0.9251, Precision=0.9167, Recall=0.9157 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=91.5%, F1 Score=0.9276, Precision=0.9153, Recall=0.9134 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=86.4%, F1 Score=0.8981, Precision=0.8644, Recall=0.8682 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "\n",
      "Votes for Loss Function: {CrossEntropyLoss(): 15}\n",
      "The Loss Function with the most votes: CrossEntropyLoss()\n",
      "Average Test Accuracy Across Folds: 91.1%\n"
     ]
    }
   ],
   "source": [
    "hyperparameters_to_tune = [\n",
    "    {'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': nn.CrossEntropyLoss()},\n",
    "    {'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': nn.NLLLoss()},\n",
    "\n",
    "]\n",
    "all_best_hyperparameters = []\n",
    "all_average_accuracies = []\n",
    "\n",
    "for _ in range(num_experiments):\n",
    "    test_accuracies_manual_tuning, best_hyperparameters_each_fold = nested_cross_validation(X, y, hyperparameters_to_tune, input_size, output_size, outer_splits=outer_splits, inner_splits=inner_splits, seed=seed)\n",
    "    all_average_accuracies.append(test_accuracies_manual_tuning)\n",
    "    all_best_hyperparameters.append(best_hyperparameters_each_fold)\n",
    "    \n",
    "loss_function_votes = {}\n",
    "\n",
    "for results in all_best_hyperparameters:\n",
    "    for hyperparameters in results:\n",
    "        loss_function = hyperparameters['loss_function']\n",
    "        loss_function_votes[loss_function] = loss_function_votes.get(loss_function, 0) + 1\n",
    "        \n",
    "best_loss_function = max(loss_function_votes, key=loss_function_votes.get)\n",
    "average_test_accuracy = np.mean(all_average_accuracies)\n",
    "print()\n",
    "print(f\"Votes for Loss Function: {loss_function_votes}\")\n",
    "print(f\"The Loss Function with the most votes: {best_loss_function}\")\n",
    "print(f\"Average Test Accuracy Across Folds: {average_test_accuracy * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9847fc7-ae48-4a4e-abaa-ce5c12caf70e",
   "metadata": {},
   "source": [
    "**Cross Entropy gives the best accuracy for most tests. This is chosen.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a9ea86-0991-4f95-a573-f6697299a515",
   "metadata": {},
   "source": [
    "### Test model on different Seeds\n",
    "We now use the selected Hyper Parameters and run the Model with these and vary the seeds in order to report some statistics on the Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f94671fe-6cb6-4806-876e-f23ca2cd23c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Fold: Test Accuracy=98.3%, F1 Score=0.9840, Precision=0.9833, Recall=0.9832 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=89.8%, F1 Score=0.9002, Precision=0.8983, Recall=0.8975 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=89.8%, F1 Score=0.8989, Precision=0.8983, Recall=0.8981 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "\n",
      "Seed 1: Average Test Accuracy Across Folds: 92.7%\n",
      "\n",
      "Outer Fold: Test Accuracy=96.7%, F1 Score=0.9676, Precision=0.9667, Recall=0.9667 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=89.8%, F1 Score=0.9086, Precision=0.8983, Recall=0.8987 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=96.6%, F1 Score=0.9687, Precision=0.9661, Recall=0.9658 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "\n",
      "Seed 42: Average Test Accuracy Across Folds: 94.4%\n",
      "\n",
      "Outer Fold: Test Accuracy=90.0%, F1 Score=0.9164, Precision=0.9000, Recall=0.8974 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=89.8%, F1 Score=0.9017, Precision=0.8983, Recall=0.8990 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=93.2%, F1 Score=0.9373, Precision=0.9322, Recall=0.9315 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "\n",
      "Seed 123: Average Test Accuracy Across Folds: 91.0%\n",
      "\n",
      "Outer Fold: Test Accuracy=90.0%, F1 Score=0.9032, Precision=0.9000, Recall=0.8989 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=89.8%, F1 Score=0.8988, Precision=0.8983, Recall=0.8981 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "Outer Fold: Test Accuracy=98.3%, F1 Score=0.9840, Precision=0.9831, Recall=0.9831 with Hyperparameters={'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': CrossEntropyLoss()}\n",
      "\n",
      "Seed 987: Average Test Accuracy Across Folds: 92.7%\n",
      "\n",
      "\n",
      "Overall Average Test Accuracy Across Seeds: 92.7%\n"
     ]
    }
   ],
   "source": [
    "all_best_hyperparameters = []\n",
    "all_test_accuracies = []\n",
    "\n",
    "seed_list = [1, 42, 123, 987]\n",
    "\n",
    "for seed in seed_list:\n",
    "    hyperparameters_to_tune = [\n",
    "        {'learning_rate': 0.01, 'hidden_neurons': 13, 'hidden_layers': 1, 'num_epochs': 100, 'loss_function': nn.CrossEntropyLoss()},\n",
    "    ]\n",
    "\n",
    "    test_accuracies_manual_tuning, best_hyperparameters_each_fold = nested_cross_validation(X, y, hyperparameters_to_tune, input_size, output_size, outer_splits=outer_splits, inner_splits=inner_splits, seed=seed)\n",
    "    all_best_hyperparameters.append(best_hyperparameters_each_fold)\n",
    "    all_test_accuracies.append(test_accuracies_manual_tuning)\n",
    "\n",
    "    average_test_accuracy = np.mean(test_accuracies_manual_tuning)\n",
    "    print()\n",
    "    print(f\"Seed {seed}: Average Test Accuracy Across Folds: {average_test_accuracy * 100:.1f}%\")\n",
    "    print()\n",
    "\n",
    "overall_average_test_accuracy = np.mean([np.mean(acc) for acc in all_test_accuracies])\n",
    "print(f\"\\nOverall Average Test Accuracy Across Seeds: {overall_average_test_accuracy * 100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04ab847-ee1c-4654-96bc-3003c5f89c58",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "This final test gives an accuracy of around 90% for the tuned model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
